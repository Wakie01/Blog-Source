---
title: Tracking without bells and whistles
comment: true
date: 2021-08-30 20:41:28
tags: CV
categories: Paper
addrlink: 1512
---


题目：跟踪没有花里胡哨



# 摘要

本文所提出的方法：通过检测进行跟踪，`Tracking-by-detection`。



对于通过检测进行跟踪，这需要以下技术：物体再识别、运动预测、遮挡处理等技术。



在本论文中，作者展示的跟踪器，可以在不专门针对跟踪任务下完成跟踪，而且，作者没有对跟踪数据进行任何训练或优化。



作者利用对象检测器的边界盒回归来预测对象在下一帧的位置，从而将检测器转换为跟踪器。



作者所提出的这种方法为三个多目标跟踪提供一个新的先进技术，这种方法是通过直接的重新识别和摄像机运动补偿来实现的。



以往的跟踪技术中，对于较小的、被遮挡的、容易丢失检测的物体，跟踪效果不太理想。



# 介绍

`Tracking-by-detection`方法对于多目标跟踪，是一个很不错的方法，它将跟踪任务简化成两步：

1. 在每一帧中独立地检测目标位置。
2. 通过跨时间链接相应的检测信息来形成跟踪。

显然，检测信息的链接是关键，它涉及到很多问题的解决，比如：在拥挤的环境中丢失检测目标、虚假检测、目标遮挡、目标交互等等。

为了解决这些问题，作者在检测目标的任务上训练神经网络，这能在复杂跟踪场景下构建目标轨迹。



文章的主要贡献：

1. 介绍了一种跟踪器，它利用检测器的回归头对目标边界框进行时间重新对齐，从而实现多目标跟踪。
2. 提出了对跟踪器的两个简单扩展：重识别的`Siamese`网络和一个运动模型。这样优化了“对于较小的、被遮挡的、容易丢失检测的物体，跟踪效果不太理想”的问题。
3. 文章所提出的回归方法与当下最好的跟踪方法相当。





# 检测器

作者倾向于将检测器转换为跟踪器，进行多目标检测。



作者使用回归器进行跟踪任务。这样做有两个优点：

1. 不需要对跟踪进行特殊的训练
2. 在跟踪过程中不需要进行优化处理，因此跟踪器可以是在线的。

至于使用什么回归器，我还不知道。



## 目标检测器

作者所提出的跟踪器中，其核心组件就是一个基于回归的检测器。



作者用`ResNet-101`数据集训练`Faster R-CNN`模型，和用`MOT17Det`行人检测数据集训练`Feature Pyramid Networks(FPN)`模型。

 

目标检测器工作流程：

1. 为了进行目标检测，`Faster R-CNN`使用`Region Proposal Network`来为每个潜在对象生成大量边界框建议。
2. 然后`Region of Interest（RoI）`池对每个边界框建议提取特征图，并将这些特征图传递到分类器头和回归器头。
3. 然后分类器头会对每个边框建议图，结合其特征图进行评分，评估它是否是个行人。
4. 而回归器头则在目标周围精确细化边界框的位置。
5. 然后检测器通过应用非最大抑制（`non-maximum-suppression,NMS`）来筛选边界框建议，从而生成最终的对象检测集。



## 跟踪器

多目标跟踪的挑战是提取空间和时间位置，即：视频帧中多个目标的轨迹。



![image-20210901151717186](.\Tracking-without-bells-and-whistles\1.png)



一个目标的轨迹，定义为：有序的目标边界框列表，即：
$$
T_k=\lbrace b_{t1}^k , b_{t2}^k , … , \rbrace
$$
其中：

- $b_{t} ^k$ ：在第t帧中目标k的边界框坐标
- $t$ ：视频的某一帧
- $k$ ：某个目标的轨迹



定义某一帧中所有目标边界框的集合为：
$$
B_t=\lbrace b_t ^{k1} , b_t ^{k2} , … \rbrace
$$
其中：

- $b_t ^{k1}$ ：第k1个目标在视频的第t帧中的边界框坐标

> 有时 $B_t=\lbrace b_t ^{k1} , b_t ^{k2} , … \rbrace$ 会写出 $D_t=\lbrace d_t ^{k1} , d_t ^{k2} , … \rbrace$ 





### 边界框回归

首先通过边界框回归，将目标前一帧`t-1`的活动轨迹扩展到当前帧`t`，即由 $b_{t-1} ^k$ 回归转变为 $b_t ^k$ 。

执行完边界框回归后，就会对以下两种情况进行清除轨迹：

1. 对于在新的帧中不见的目标或者被非目标对象遮挡的目标，如果分类器对它们新的评分 $s_t ^k$ 小于 $\sigma _{active}$  ，就会被清除。
2. 当目标间被遮挡住时，就会应用非最大抑制（`non-maximum-suppression,NMS`）



### 边界框初始化

为了考虑新的目标，目标检测器会做以下事情：

1. 提供某一帧中的所有目标边界框的集合，即：$D_t$ 。
2. 当当前帧的目标与之前帧的目标的`IoU`值（`Intersection over Union`，联合体上的交点）小于 $\lambda _{new}$ 时，则认为该目标为新目标。



## 跟踪器扩展

作者对`vanilla`跟踪器进行了两个扩展：

1. 运动模型
2. 重新识别算法

这两种方法目的都是提高帧之间的身份保持能力。



### 运动模型

之前的运动设定是这样的：目标的位置在帧与帧之间只发生轻微的变化。而这种设定显然在以下两种场景下不行：

1. 摄像机运动幅度较大的场景
2. 视频帧速率较低的场景

前一帧的目标，在后一帧中全部都没有，这显然是不行的。

因此，作者使用两种类型的运动模型，来改进未来帧中目标边界框的位置：

1. 对于摄像机运动的场景：

   作者使用了一种简单的摄像机运动补偿（`camera motion compensation,CMC`）方法，该方法最大化增加相关系数（`Enhanced Correlation Coefficient,ECC`）来进行图像配准，从而实现帧与帧之间的对齐。

2. 对于视频帧速率较低的场景：

   对所有目标应用恒定速假设（`constant velocity assumption，CVA`）



### 重新识别算法

为了使跟踪器保持在线，作者使用了一种短期的再识别方法，该方法基于`Siamese`神经网络生成的外观向量。

为此，作者对杀死的目标，存储固定帧数的样本，然后将这些样本的目标轨迹和新检测的目标轨迹，进行比较嵌入空间距离（`embedding space distance`），然后通过阈值进行重新识别。

其中，嵌入空间距离是通过`Siamese CNN`和每个边界框的外观特征向量计算的。

此外，为了尽量避免重识别错误，只考虑杀死的目标轨迹和新的目标边界框，并且新的目标边界框具有足够大的`IoU`。





# 补

## 多目标跟踪（MOT）评价指标：

![img](.\Tracking-without-bells-and-whistles\2.png)

![img](.\Tracking-without-bells-and-whistles\3.png)